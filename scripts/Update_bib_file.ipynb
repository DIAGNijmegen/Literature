{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from get_biblatex import GetBiblatex\n",
    "from bib_handling_code.processbib import read_bibfile\n",
    "from bib_handling_code.processbib import save_to_file\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "from semanticscholar import SemanticScholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' KM: Remove this fn from here. Dre to update GenerateCSVFile with method like this which handles no-doi items\n",
    "def remove_blacklist_items(df_new_items):\n",
    "    blacklisted_items = pd.read_csv(\"./script_data/blacklist.csv\")\n",
    "    initial_length = len(df_new_items)\n",
    "    df_new_items = df_new_items[~df_new_items['ss_doi'].isin(blacklisted_items['doi'].unique().tolist())] # remove blacklisted dois\n",
    "    df_new_items = df_new_items[~df_new_items['ss_id'].isin(blacklisted_items['ss_id'].unique().tolist())] # remove blacklisted dois\n",
    "\n",
    "    print(f\"{initial_length-len(df_new_items)} items removed from newly found items.\")\n",
    "    return df_new_items\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_item_to_blacklist(item): # item here is a row from the manually checked csv file\n",
    "    #Add item to blacklist.csv\n",
    "    move_to_blacklist = {\n",
    "        'staff_id': item.get('staff_id', None),\n",
    "        'staff_name': item.get('staff_id', None),\n",
    "        'ss_year': item.get('ss_year', None),\n",
    "        'ss_id': item.get('ss_id', None),\n",
    "        'title': item.get('ss_title', None),\n",
    "        'doi': item.get('ss_doi', None),\n",
    "        'Should be in diag.bib': 'no',\n",
    "        'Reason': item.get('Blacklist reason', None)\n",
    "    }\n",
    "\n",
    "    return move_to_blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_blacklist_csv(blacklist_csv, blacklist_entries): #blacklist_csv is a df\n",
    "    # Add all items to blacklist.csv\n",
    "    blacklist_csv = pd.concat([blacklist_csv, pd.DataFrame(blacklist_entries)], ignore_index=True)\n",
    "\n",
    "    # Save blacklist.csv\n",
    "    blacklist_csv.to_csv('./script_data/blacklist.csv', index=False)\n",
    "    return f\"{len(blacklist_entries)} items added to blacklist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code to get citations from semantic scholar. If there are multiple ss_ids, we should get the number of citations for each of them and sum the two (or more?) values.\n",
    "def get_citations(semantic_scholar_ids):\n",
    "    dict_cits = {}\n",
    "    for ss_id in semantic_scholar_ids:\n",
    "        sch = SemanticScholar()\n",
    "        paper = sch.get_paper(ss_id)\n",
    "        paper_id = paper['paperId']\n",
    "        dict_cits[paper_id] = len(paper['citations'])\n",
    "    return dict_cits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_bib_info(diag_bib_file, item): #diag_bib_file is the file read in as a string, item is row from csv\n",
    "    #Get DOI information\n",
    "    citations = 0\n",
    "    # if isinstance(item['ss_id'], list):\n",
    "    #     for ss_id in item['ss_id']:\n",
    "    #         citations += get_citations(ss_id)\n",
    "    # else:\n",
    "    #     citations = get_citations(item['ss_id'])\n",
    "\n",
    "    # make sure doi is not already in diag.bib\n",
    "    if item['ss_doi'] in diag_bib_file:\n",
    "        return None\n",
    "\n",
    "    # Get BibLatex information based on DOI if not in the file\n",
    "    reader = GetBiblatex(doi=item['ss_doi'], diag_bib=diag_bib_file, num_citations=citations)\n",
    "    bibtext = reader.get_bib_text()\n",
    "\n",
    "    # Return the bibtext if it is not 'empty', otherwise return None\n",
    "    return bibtext if bibtext != 'empty' else None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_ss_id_to_existing_bibkey(diag_bib_raw, ss_id, bibkey):\n",
    "    \n",
    "    #Update bibkey with ss_id\n",
    "    for ind, entry in enumerate(diag_bib_raw):\n",
    "        if entry.type == 'string':\n",
    "            continue\n",
    "            \n",
    "        print(entry.key)\n",
    "        # if we found the relevant key\n",
    "        if bibkey == entry.key:\n",
    "            # if there is already something in all_ss_ids\n",
    "            if 'all_ss_ids' in entry.fields.keys():\n",
    "                if not entry.fields['all_ss_ids'] == '{' + str(ss_id) + '}': # this should never happen, right? (from Keelin!)\n",
    "                    previous = literal_eval(entry.fields['all_ss_ids'].strip('{}'))\n",
    "                    new = ss_id\n",
    "                    combined = list(set(previous) | set([new]))\n",
    "                    # update the entry\n",
    "                    entry.fields['all_ss_ids'] = '{' + str(combined) + '}'\n",
    "            # if there is no ss_id here yet just add this single one\n",
    "            else:   \n",
    "                    entry.fields['all_ss_ids'] = '{' + str(ss_id) + '}'\n",
    "            # put the updated entry back into the list\n",
    "            diag_bib_raw[ind] = entry\n",
    "            print(str(ss_id), 'added to diag.bib')\n",
    "            return diag_bib_raw\n",
    "        \n",
    "    # if we haven't returned by now then we failed to update \n",
    "    print('failed to add ss_id to diag.bib', str(ss_id), str(bibkey))\n",
    "    return diag_bib_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_citation_count(path_diag_bib):\n",
    "    \n",
    "    diag_bib_raw = read_bibfile(None, path_diag_bib)\n",
    "    for entry in diag_bib_raw:\n",
    "        flag=0\n",
    "        if entry.type == 'string':\n",
    "            continue\n",
    "        if 'all_ss_ids' in entry.fields:\n",
    "            all_ss_ids = []\n",
    "            ss_ids = entry.fields['all_ss_ids'].translate(str.maketrans('', '', string.punctuation)).split(' ')\n",
    "            if len(ss_ids) > 1:\n",
    "                all_ss_ids.extend(ss_ids)\n",
    "            else:\n",
    "                all_ss_ids.append(ss_ids[0])\n",
    "            dict_cits = get_citations(all_ss_ids)\n",
    "            n_cits = 0\n",
    "            for key in dict_cits.keys():\n",
    "                n_cits += dict_cits[key]\n",
    "            if 'gscites' in entry.fields:\n",
    "                if n_cits > int(entry.fields['gscites'].strip('{}')):\n",
    "                    entry.fields['gscites'] = '{' + str(n_cits) + '}'\n",
    "            else:\n",
    "                entry.fields['gscites'] = '{' + str(n_cits) + '}'\n",
    "    return diag_bib_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load manually_checked\n",
    "manually_checked = pd.read_csv(\"./script_data/manual_check.csv\")\n",
    "# manually_checked = remove_blacklist_items(manually_checked)     # This should be done before actually manually checking\n",
    "\n",
    "# POTENTIAL TO-DO CREATE ACTION MAPPINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through all items in the manually checked csv\n",
    "blacklist_items = []\n",
    "items_to_add = ''\n",
    "items_to_update = []\n",
    "\n",
    "#TODO: Make sure new items or updated items in the bib-file include pmid and doi if they did not previously\n",
    "\n",
    "for index, bib_item in manually_checked.iterrows():\n",
    "    print(f\"Working on {index}/{len(manually_checked)}\")\n",
    "    # Make sure item is manually checked\n",
    "    if \",\" in bib_item['action']:\n",
    "        print(f\"{bib_item['ss_id']} has not been checked yet, make sure only 1 action is mentioned\")\n",
    "        continue\n",
    "        #TODO: we will later work from a dropdown-list rather than a comma separated set of actions so this probably will need updating\n",
    "\n",
    "    # Add new item to diag.bib\n",
    "    elif \"add new item\" in bib_item['action']:\n",
    "       bib_item_text = get_bib_info(diag_bib, bib_item)\n",
    "\n",
    "       if bib_item_text is not None:\n",
    "           items_to_add += bib_item_text\n",
    "       else:\n",
    "           print(f\"Unable to gather information for {bib_item['ss_doi']}\")\n",
    "           # TO-DO APPEND items we were unable to add\n",
    "\n",
    "    # Add ss_id to already existing doi in diag.bib\n",
    "    elif \"add ss_id\" in bib_item['action']:\n",
    "        # just store a list of these items for now and we will update the file at the end\n",
    "        items_to_update += [bib_item]\n",
    "        \n",
    "    # Get items to blacklist\n",
    "    elif \"blacklist\" in bib_item['action']:\n",
    "        blacklist_item = get_item_to_blacklist(bib_item)\n",
    "        blacklist_items.append(blacklist_item)\n",
    "\n",
    "    # Get None items\n",
    "    elif 'None' in bib_item['action']:\n",
    "        continue\n",
    "\n",
    "    # TODO: NOTIFY IF NOTHING IS DONE WITH AN ITEM (NO-MATCH)\n",
    "\n",
    "# First we open the bib file, add the completely new bib entries and save it:\n",
    "#Load diag.bib as a string\n",
    "cwd = os.getcwd()\n",
    "parent_directory = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "#TODO: in the end when this script is routine this should just read the live diag.bib\n",
    "diag_bib_path = os.path.join(parent_directory, 'scripts/script_data/diag_ss.bib')\n",
    "with open(diag_bib_path, encoding=\"utf8\") as bibtex_file:\n",
    "    diag_bib = bibtex_file.read()\n",
    "# append the new items to the string\n",
    "diag_bib += items_to_add  \n",
    "# save the file to disk (temporarily commented)\n",
    "# with open(diag_bib_path, encoding=\"utf8\") as bibtex_file:\n",
    "#    bibtex_file.write(diag_bib)\n",
    "\n",
    "# TO-DO FILE STILL HAVE TO BE SAVED\n",
    "# TO-DO: RE-READ BIB FILE AND UPDATE SS_IDS LIST FROM CODE IN FOR LOOP\n",
    "\n",
    "# Second we re-open the bib file using the read_bibfile method and update existing items with new ss_ids\n",
    "diag_bib_raw = read_bibfile(None, diag_bib_path)\n",
    "for item_to_update in items_to_update:\n",
    "    diag_bib_raw=add_ss_id_to_existing_bibkey(diag_bib_raw, item_to_update[\"ss_id\"], item_to_update[\"bibkey\"])\n",
    "# and save the bibfile with the newly added ss_ids (temporarily commented)\n",
    "# save_to_file(diag_bib_raw, diag_bib_path)\n",
    "\n",
    "# Third we update the blacklist (temporarily commented)\n",
    "blacklist = pd.read_csv('./script_data/blacklist.csv')\n",
    "# update_blacklist_csv(blacklist, blacklist_items)\n",
    "\n",
    "# TODO: Here we should provide a report of rows where we did not know what to do or we failed to do the action\n",
    "print(\"DONE with processing manually checked items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count = items_to_add.count('{yes}')\n",
    "print(f\"Newly added items: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Blacklisted items: {len(blacklist_items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Update citation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_diag_bib = os.path.join('script_data/', 'diag_ss.bib')\n",
    "update_citation_count(path_diag_bib)\n",
    "path_output_diag_bib = os.path.join('script_data/', 'diag_ss_new.bib')\n",
    "save_to_file(diag_bib_raw, None, path_output_diag_bib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = \"string\"\n",
    "b = None\n",
    "if b is not None:\n",
    "    c = a + b\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit_env",
   "language": "python",
   "name": "lit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
